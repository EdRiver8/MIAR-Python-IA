{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146c8085-6432-4ce4-b308-19a9bcea9a10",
   "metadata": {},
   "source": [
    "# Primera Practica con Pandas y PlotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e45209e-69c1-42bf-8f39-628a5b6bdbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc598304-54ad-4dce-896b-eae56587f34c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\edwriver\\\\Downloads\\\\cursopandas\\\\dataset\\\\1.3\\\\Info_pais.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43medwriver\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDownloads\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mcursopandas\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m1.3\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mInfo_pais.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mISO-8859-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dwein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dwein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dwein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dwein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dwein\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\edwriver\\\\Downloads\\\\cursopandas\\\\dataset\\\\1.3\\\\Info_pais.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\edwriver\\Downloads\\cursopandas\\dataset\\1.3\\Info_pais.csv', encoding=\"ISO-8859-1\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09adf2-5a03-4f71-97a8-8b52ecdb5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f5d7f-0eab-4caf-a655-961af484aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33efe61-4de7-43d2-b4f2-9eb0b74f5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e0990-ae83-47c4-97d8-f36ac5c02380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order = df.sort_values(\"Esperanza de vida\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6429397-5adf-4748-9729-29bb783d02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e3e83-5a03-418a-a395-3b58b49c893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b844b03",
   "metadata": {},
   "source": [
    "## Uso de numpy\n",
    "### Sirve como base para otras librerias como pandas, su fuerte es manejos de array sobre todo con datos numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca62b94-2d07-4ad5-bf8f-145645ff4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio base * altura \n",
    "bases_rec = np.array([10, 20, 30])\n",
    "alturas_rec = np.array([5, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2295f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_rec = bases_rec * alturas_rec / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_rec > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ceebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_rec[areas_rec > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matices con numpy\n",
    "res = np.array([10, 20, 30, 40, 50])\n",
    "res2 = np.array([5, 15, 25, 35, 45])\n",
    "res + res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d71226",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar una posicion dada de la matriz, por ejemplo la fila 1, columna 2 = 6\n",
    "matriz[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora mostrar toda la fila 0\n",
    "matriz[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de613f",
   "metadata": {},
   "source": [
    "## Estadistica con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un set de datos de formas aleatoria\n",
    "matriz_aleatoria = np.random.normal(3, 1.5, 10000)\n",
    "matriz_aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_aleatoria.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224294ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(matriz_aleatoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_aleatoria.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rango_95 = (matriz_aleatoria.mean() - 2*matriz_aleatoria.std(), matriz_aleatoria.mean() + 2*matriz_aleatoria.std())\n",
    "rango_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bffe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de Matplotlib para graficar histogramas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f841d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(matriz_aleatoria, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad493cc1",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "* Esta construida basada en numpy\n",
    "* Su principal elemento es el dataframe (Columbas - variables, filas - datos)\n",
    "* Permite manipular gran cantidad de datos por medio del calculo vectorial\n",
    "* Su diferencia con un array de numpy, es que en este los datos son del mismo tipo, mientras que en pandas pueden variar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371eadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe de pais, capital y poblacion\n",
    "data = {\n",
    "    'Pais': ['Argentina', 'Brasil', 'Chile', 'Uruguay'],\n",
    "    'Capital': ['Buenos Aires', 'Brasilia', 'Santiago', 'Montevideo'],\n",
    "    'Poblacion': [45000000, 210000000, 19000000, 3500000]\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a638f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paises = pd.DataFrame(data)\n",
    "df_paises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos desde un archivo CSV a un DataFrame de pandas\n",
    "# agregar la columna 'Continente' al DataFrame\n",
    "df_paises['Continente'] = ['America del Sur', 'America del Sur', 'America del Sur', 'America del Sur']\n",
    "df_paises.to_csv('paises.csv', index=False) # Guardar el DataFrame en un archivo CSV\n",
    "df_nuevos_paises = pd.read_csv('paises.csv') # Leer el archivo CSV en un nuevo DataFrame\n",
    "df_nuevos_paises\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdad0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: Guardar el DataFrame ordenado en un nuevo archivo CSV\n",
    "df_order.to_csv('paises_ordenados.csv', index=False)\n",
    "df_nuevos_ordenados = pd.read_csv('paises_ordenados.csv')\n",
    "df_nuevos_ordenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1167ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar desde una ruta del sistema\n",
    "df_peatones = pd.read_csv(\n",
    "    r\"C:\\Users\\edwriver\\Downloads\\cursopandas\\dataset\\5.3\\PEATONES_2020.csv\", # ruta del archivo, la r sirve para evitar problemas con las barras invertidas\n",
    "    encoding=\"ISO-8859-1\", # codificacion del archivo\n",
    "    delimiter=\";\", # separador de columnas\n",
    "    index_col=2, # columna a usar como indice\n",
    "    nrows=10000, # numero de filas a leer\n",
    "    header=None # indicar que el archivo no tiene encabezado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84984fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.info()  # Mostrar informacion del DataFrame, con su conteo de 10000 registros seleccionados al ser creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd514f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.describe() # realizar estadisticas descriptivas del DataFrame de los valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantos valores erroneos o nulos hay en el DataFrame\n",
    "df_peatones.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cafde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.shape # muestra la cantidad de filas y columnas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7087c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones = pd.read_csv(\n",
    "    r\"C:\\Users\\edwriver\\Downloads\\cursopandas\\dataset\\5.3\\PEATONES_2020.csv\",  # ruta del archivo, la r sirve para evitar problemas con las barras invertidas\n",
    "    encoding=\"ISO-8859-1\",  # codificacion del archivo\n",
    "    delimiter=\";\",  # separador de columnas\n",
    "    index_col=2,  # columna a usar como indice\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b277922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea14a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones[\"PEATONES\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aded7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones[\"PEATONES\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadistico de Rango Intercuartilico (IQR)\n",
    "df_full_peatones[\"PEATONES\"].quantile(0.75) - df_full_peatones[\"PEATONES\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b12609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cual es el rango de fechas del dataset\n",
    "df_full_peatones[\"FECHA\"].min() # fecha mas antigua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a859e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones[\"FECHA\"].max() # fecha mas reciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe44922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.describe() # realizar estadisticas descriptivas del DataFrame de los valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eac2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuantos valores erroneos tiene la columna peatones\n",
    "df_peatones[3].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cual es la mediana de dicha variable?\n",
    "df_full_peatones.PEATONES.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334470dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna acumulativa de peatones\n",
    "df_full_peatones[\"PEATONES_ACUMULADOS\"] = df_full_peatones[\"PEATONES\"].cumsum()\n",
    "df_full_peatones\n",
    "# Ubicar la columna PEATONES_ACUMULADOS despues de la columna PEATONES\n",
    "cols = df_full_peatones.columns.tolist()\n",
    "cols.insert(cols.index(\"PEATONES\") + 1, cols.pop(cols.index(\"PEATONES_ACUMULADOS\")))\n",
    "df_full_peatones = df_full_peatones[cols]\n",
    "df_full_peatones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ee2db",
   "metadata": {},
   "source": [
    "## Limpiar Data\n",
    "\n",
    "- Eliminar valores duplicados (filas duplicadas, exactamente misma info) cuando es necesario df.drop_duplicates(), se puede aplicar a todo el df o a una sola columna\n",
    "- Eliminar nan: df.dropna(), se puede aplicar a todo el df o a una sola columna\n",
    "- Eliminar columnas que no se requieren: df.drop('nombre_columna', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Limpiar el DataFrame de peatones eliminando filas con valores nulos en la columna PEATONES\n",
    "valores_duplicados = df_full_peatones.duplicated()\n",
    "valores_duplicados.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ca66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones.shape # para validar cuantos datos hay antes de eliminar los duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f45533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora si, limpiar los valores duplicados\n",
    "df_full_peatones_cleaned = df_full_peatones.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c587a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones_cleaned.shape # para validar cuantos datos hay despues de eliminar los duplicados\n",
    "# Ahora si se quiere eliminar duplicados y reemplazar en el mismo DataFrame de una vez, se puede hacer asi:\n",
    "# df_full_peatones.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores erroneos o nulos en la columna PEATONES despues de limpiar los duplicados\n",
    "df_full_peatones_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6483a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_peatones_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_erroneos = 288749 - 284866\n",
    "valores_erroneos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72911b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_erroneos = (valores_erroneos / 288749) * 100\n",
    "porcentaje_erroneos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72fa70",
   "metadata": {},
   "source": [
    "## Interpolar Data\n",
    "\n",
    "- Obtener un nuevo valor a partir de un conjunto dado, puede ser un dato intermedio que aun no se tiene y que se puede calcular entre dos puntos\n",
    "- Si existen valores erroneos y NO queremos descartar el registro -> df_fill[\"A\"].fillna(df_fill[\"A\"].median(), inplace=True), esto lo que hace, es reemplazar los valores NaN por su mediana y no perder registros por NaN\n",
    "\n",
    "* Mostrar los datos erroneos en la tabla (NaN) con df['nombre columna'].fillna(valor, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c801e3",
   "metadata": {},
   "source": [
    "## Filtrar datos en df con Pandas\n",
    "\n",
    "- Se pone la columna a la cual se quiere aplicar el filtro, seguido de una condicion usando los comparadores logicos: df[df[\"Edad\"]>17], df[df[\"Edad\"]>notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d62709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones = pd.read_csv(\n",
    "  r\"C:\\Users\\edwriver\\Downloads\\cursopandas\\dataset\\5.3\\PEATONES_2020.csv\", \n",
    "  encoding=\"ISO-8859-1\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear un nuevo df con filtrado por fechas\n",
    "df_peatones_filtered = df_peatones[\n",
    "    (df_peatones[\"FECHA\"] >= \"01/01/2020\") & (df_peatones[\"FECHA\"] <= \"30/06/2020\")\n",
    "]\n",
    "df_peatones_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones_filtered.DISTRITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peatones_filtered.DISTRITO.count() # muestra la cantidad de registros en la columna DISTRITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar los valores unicos de la columna DISTRITO\n",
    "df_peatones_filtered.DISTRITO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264933b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_distrito = df_peatones_filtered[\"DISTRITO\"] == \"Centro\"\n",
    "mascara_distrito.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31813401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mascara_distrito]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77add14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_distrito.notna() # verificar cuales valores no son nulos y devuelve True si no son nulos o False si son nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar por distrito CENTRO\n",
    "df3_distrito_centro = df_peatones_filtered[mascara_distrito]\n",
    "df3_distrito_centro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora unir las dos condiciones de filtrado en un solo DataFrame\n",
    "df_distrito_centro_jan_jun = df_peatones[\n",
    "    (df_peatones[\"FECHA\"] >= \"01/01/2020\")\n",
    "    & (df_peatones[\"FECHA\"] <= \"30/06/2020\")\n",
    "    & (df_peatones[\"DISTRITO\"] == \"Centro\")\n",
    "]\n",
    "df_distrito_centro_jan_jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distrito_centro_jan_jun.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea61c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
